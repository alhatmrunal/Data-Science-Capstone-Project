# -*- coding: utf-8 -*-
"""EDA_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12rO4nFA8MhZLpmNSqWyhbeSeF3KH3-Uz
"""

import pandas as pd
import numpy as num
import matplotlib.pyplot as plt
import seaborn as sns

#read the file
df = pd.read_csv(r'/CAR DETAILS.csv')
df

df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

df.head()

df.info()

df.describe()

df.isna()

df.shape

df.columns

# Split the column name to get the model of the car
df["model"] = df.name.apply(lambda x : ' '.join(x.split(' ')[:1]))
df['model'].value_counts()

# Check null values in dataset
df.isnull().sum()

df.dropna()

# Check duplicated row in dataset
df[df.duplicated()]

# Drop all duplicated row
df = df.drop_duplicates()

df.shape

# View unique values from categorical features
categorical = [col for col in df.columns if df[col].dtypes == 'O']

for col in categorical:
  print(df[col].unique())

"""Exploratory data analysis"""

car = df.copy()

#Model Distribution
car["model"].value_counts().index

def percent(ax):
    heightlst = []
    for i in ax.patches:
        heightlst.append(i.get_height())
    total = sum(heightlst)

    for i in ax.patches:
        x = i.get_x()+0.2
        height = i.get_height()+4.3
        value = ("{0:.2f}".format((i.get_height()/total)*100)+'%')

        ax.text(x, height, value, fontsize=14,color='black')

# Plot of Car Models Distribution
figure = plt.figure(figsize=(12,8))
plt.title('Car Models Distribution', fontsize=18)
plot = sns.countplot(x="model", data=car, order = car['model'].value_counts().index[:5], palette='Blues_r')
percent(plot)

plt.show()

def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Blues_r', verbose=True):
    '''
    Helper function that gives a quick summary of a given column of categorical data
    Arguments
    =========
    dataframe: pandas dataframe
    x: str. horizontal axis to plot the labels of categorical data, y would be the count
    y: str. vertical axis to plot the labels of categorical data, x would be the count
    hue: str. if you want to compare it another variable (usually the target variable)
    palette: array-like. Colour of the plot
    Returns
    =======
    Quick Stats of the data and also the count plot
    '''
    if x == None:
        column_interested = y
    else:
        column_interested = x
    series = dataframe[column_interested]
    print(series.describe())
    print('mode: ', series.mode())
    if verbose:
        print('='*80)
        print(series.value_counts())

    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)
    plt.show()

categorical_summarized(car, x='fuel')

categorical_summarized(car, x='fuel')

categorical_summarized(car, x='transmission')

categorical_summarized(car, x='owner')

# Subplot of Categorical Summary
plt.figure(figsize=(18,8))

plt.subplot(2,2,1)
plt.title('Fuel Summary', fontsize=18)
sns.countplot(data=car, x='fuel', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,2)
plt.title('Transmission Summary', fontsize=18)
sns.countplot(data=car, x='transmission', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,3)
plt.title('Owner Summary', fontsize=18)
sns.countplot(data=car, x='owner', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,4)
plt.title('Seller Type Summary', fontsize=18)
sns.countplot(data=car, x='seller_type', palette='Blues_r')
plt.xlabel('')

plt.tight_layout()
plt.show()

plt.figure(figsize=(10,10))
plt.title('Correlation Matrix', fontsize=18)
sns.heatmap(car.corr(), cbar=True, annot=True, cmap='Blues')

#Correlation Between selling_price and km_driven
plt.figure(figsize=(18,8))
plt.title('km_driven by selling_price Distribution', fontsize=18)
sns.scatterplot(data=car, x='km_driven', y='selling_price')

plt.ticklabel_format(style='plain', axis='y')

#Correlation Between selling_price and year
plt.figure(figsize=(18,8))
plt.title('year by selling_price Distribution', fontsize=18)
sns.scatterplot(data=car, x='year', y='selling_price')

plt.ticklabel_format(style='plain', axis='y')

#How does year affects km_driven?
plt.figure(figsize=(12,10))
plt.title('year by km_driven Distribution', fontsize=18)
sns.histplot(data=car, x='year', y='km_driven', bins=100)
#plt.ticklabel_format(style='plain', axis='x')

#Detailed Analysis in selling_price, km_driven, yearÂ¶
pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='selling_price', ascending=False)

pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='km_driven', ascending=False)

pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='year', ascending=False)

#How does Categorical Feature affects selling_price
plt.figure(figsize=(24,16))

plt.subplot(2,2,1)
plt.title('Fuel by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='fuel', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,2)
plt.title('Transmission by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='transmission', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,3)
plt.title('Owner by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='owner', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,4)
plt.title('Seller_type by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='seller_type', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')

"""Multivariate Exploratory data analysis"""

sns.pairplot(data=df)
plt.show()

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True)
plt.show()

"""Independent and Dependent Variables

"""

df.columns

data={
      'year' :[2007, 20012, 2017],
      'km_driven' :[70000,100000, 46000],
      'selling_price' :[60000, 600000, 250000 ]
      }
df = pd.DataFrame(data)

#Splitting Data
X = df.drop('year', axis=1)#Features (all columns except 'year')

y = df['year']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2 , random_state=20)

#Applying Model
from sklearn.linear_model import LinearRegression

model= LinearRegression()

model.fit(X_train,y_train)

y_pred = model.predict(X_test)

from sklearn.preprocessing import StandardScaler

scaler= StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.preprocessing import MinMaxScaler
scaler =MinMaxScaler()
X_normalized = scaler.fit_transform(X)

import seaborn as sns
import matplotlib.pyplot

sns.pairplot(df)
#Exploring data distribution and relationships
plt.show()

df.to_csv('cleaned_data.csv',index=False)

from sklearn.metrics import mean_squared_error,r2_score

#Evaluate the model
mse= mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

r2= r2_score(y_test,y_pred)
print(f'R-squared: {r2}')

#Plotting the predictions against the actual values

plt.scatter(X_test['km_driven'], y_test, color=(0.2,0.4,0.6), label='Actual')
plt.scatter(X_test['km_driven'], y_pred, color=(1, 0, 0, 1), label='Predicted')
plt.xlabel('km_driven')
plt.ylabel('year')
plt.legend()
plt.show()

#Model Summary
import statsmodels.api as sm
X= sm.add_constant(X_train)
model = sm.OLS(y_train,X).fit()
print(model.summary())

from sklearn.metrics import mean_absolute_error
import numpy as np

y.test = np.array([y_test])
y.pred = np.array([y_pred])

mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) *100
print(f'MAPE: {mape: .2f}%')

import pandas as pd
import seaborn as sns

# Assuming 'df' is your DataFrame
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True)

from sklearn.linear_model import Lasso

# Assuming X_train and y_train are your training data
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
importances = np.abs(lasso.coef_)

df=pd.read_csv(r'/content/cleaned_data.csv')

from sklearn.metrics import mean_absolute_error
import numpy as np

y.test = np.array([y_test])
y.pred = np.array([y_pred])

mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) *100
print(f'MAPE: {mape: .2f}%')

"""20 data points from the CAR DETAILS"""

data_1 = pd.read_csv(r'/content/Car_details2.csv')
data_1

data_1.head()

data_1.info()

data_1.describe()

data_1.isna()

data_1.shape

data_1.columns

# Check null values in dataset
data_1.isnull().sum()

data_1.dropna()

# Check duplicated row in dataset
data_1[data_1.duplicated()]

# Drop all duplicated row
data_1= data_1.drop_duplicates()

data_1.shape

# View unique values from categorical features
categorical1 = [col for col in data_1.columns if data_1[col].dtypes == 'O']

for col in categorical1:
  print(data_1[col].unique())

data_1.columns

data2={
      'year' :[2007, 20012, 2017],
      'km_driven' :[70000,100000, 46000],
      'selling_price' :[60000, 600000, 250000 ]
      }
data_1 = pd.DataFrame(data2)

X1 = data_1.drop('year', axis=1)#Features (all columns except 'year')

y1 = data_1['year']

from sklearn.model_selection import train_test_split
X1_train,X1_test,y1_train,y1_test=train_test_split(X1,y1,test_size=0.2 , random_state=20)

from sklearn.linear_model import LinearRegression

model1= LinearRegression()

model1.fit(X1_train,y1_train)

y1_pred = model1.predict(X1_test)

from sklearn.preprocessing import StandardScaler

scaler1= StandardScaler()
X1_scaled = scaler.fit_transform(X1)

from sklearn.preprocessing import MinMaxScaler
scaler1 =MinMaxScaler()
X1_normalized = scaler.fit_transform(X1)

import seaborn as sns
import matplotlib.pyplot

sns.pairplot(data_1)
plt.show()

data_1.to_csv('cleaned_data_1.csv',index=False)

from sklearn.metrics import mean_squared_error,r2_score

mse1= mean_squared_error(y1_test, y1_pred)
print(f'Mean Squared Error: {mse1}')

from sklearn.linear_model import Lasso

# Assuming X_train and y_train are your training data
lasso_1= Lasso(alpha=0.1)
lasso_1.fit(X1_train, y1_train)
importances_1 = np.abs(lasso_1.coef_)

data_1=pd.read_csv(r'/content/cleaned_data_1.csv')

from sklearn.metrics import mean_absolute_error
import numpy as np

y1.test = np.array([y1_test])
y1.pred = np.array([y1_pred])

mape1 = np.mean(np.abs((y1_test - y1_pred) / (y1_test + 1e-8))) *100
print(f'MAPE: {mape1: .2f}%')

